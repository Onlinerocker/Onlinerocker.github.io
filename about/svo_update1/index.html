<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 2.25.3"/><link as="script" rel="preload" href="/webpack-runtime-9ed386a0224f94bdbae9.js"/><link as="script" rel="preload" href="/framework-712d0c71a05a512b21eb.js"/><link as="script" rel="preload" href="/app-c9959bfdc16894310609.js"/><link as="script" rel="preload" href="/commons-a30d9b8c89d158d4c38c.js"/><link as="script" rel="preload" href="/component---src-pages-svo-update-1-js-6dffdd8aef8b45458b16.js"/><link as="fetch" rel="preload" href="/page-data\svo_update1\page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data\app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous"/><nav class="navbar navbar-expand navbar-dark bg-dark"><span class="navbar-brand"><img src="/leaf.png" width="42" height="30" class="d-inline-block align-top" alt=""/></span><span class="navbar-brand">Gabe Caldwell</span><div class="mr-auto navbar-nav"><div class="nav-item"><a href="/" data-rb-event-key="/" class="nav-link">Projects</a></div><div class="nav-item"><a href="/resume" data-rb-event-key="/resume" class="nav-link">Resume</a></div><div class="nav-item"><a href="/blog" data-rb-event-key="/blog" class="nav-link">Blog</a></div><div class="nav-item"><a href="/about" data-rb-event-key="/about" class="nav-link">About</a></div></div></nav><div class="container-fluid"><br/><div style="max-width:1200px" class="card"><div class="card-header" style="background:#EEEEEE">6/3/2022</div><div class="card-body"><div class="card-title h5"><h2>SVO Ray Tracer Update #1</h2></div><a href="https://github.com/Onlinerocker/SVO">Project&#x27;s GitHub Repo</a><br/><br/><i>Screenshot of the application thus far</i><br/><img src="../svo_screenshot_update1.PNG" style="width:80%;max-width:1000px;padding-right:19px" class=""/><br/><br/><div class="card-title h5">Dependencies</div>I decided to use SDL2 for window management and input. This means I don’t have to interface with windows APIs and basically skip right to rendering things.<br/><br/>For the rendering backend I decided to go with DX11. I considered using OpenGL, but DX is the native windows API, so it seemed like the natural choice. DX12 was also a possibility, however the bulk of my code is happening inside a pixel shader running on a full-screen quad. This is something I could easily achieve using DX11 and the increased flexibility of DX12 would serve little value (it would likely just amount to more boiler plate).<br/><br/>I’m using GLM for my math library. It offers lots of functionality and I’m already familiar with it, so it’s the obvious choice.<br/><br/>Lastly, I’m using Dear ImGui for debug windows. The library has backends for a variety of project stacks, including ones using DX11 and SDL2 together. Additionally, Dear ImGui is an immediate mode user interface. This means the interface is re-rendered every frame even if nothing has changed. While this may be slower than the typical retained mode UI, it’s intuitive to work with and easy to integrate in the context of a real time graphics application. Another simplifying consequence of this is it doesn’t require any asynchronous calls or decoupling input/rendering. Input detection is done inside the same function that initiates rendering since both happen every frame. The function returns true if input has caused a state change to the corresponding UI element and false otherwise.<br/><br/>After adding the DX11/SDL2 Dear ImGui backend to my project, I was easily able to bootstrap the library by referencing an example project on the library’s GitHub page.<br/><br/><div class="card-title h5">Getting Started</div>After integrating my dependencies, I was ready to start writing code. I wrote typical DX11 boiler plate code to create my swap chain, device, and device context. After this, I created a vertex buffer to hold six vertices corresponding to a full screen quad (three vertices for each triangle in the quad).<br/><br/>A very (very) basic vertex shader was needed to transfer the vertex positions to the pixel shader. It doesn’t transform the vertex position at all, it just passes it along to the pixel shader.<br/><br/><p class="card-text" style="font-family:monospace;color:white;background:#333333;padding:10px">struct VertOut<br/>{<br/>    <!-- -->float4 pos : SV_POSITION;<br/>}<br/><br/>VertOut vertexMain(float4 position : POSITION)<br/>{<br/>    <!-- -->VertOut o;<br/>    <!-- -->o.pos = position;<br/>    <!-- -->return o;<br/>}</p><br/>Additionally, I also needed a pixel shader. I started by just outputting red to the screen. This allowed me to debug my full screen quad and vertex buffer quickly. Once the screen was completely red, I moved on to writing the pixel shader.<br/><br/>All of the voxel ray tracing and rendering is going to be done inside this pixel shader. Debugging and positioning the camera in GPU applications can be tricky (and annoying) so I wanted to start with something I was familiar with: a sphere ray marcher. I’ve written tens of ray marchers, so I was able to get this up and running without a head ache. This allowed me to ensure my camera and object positions were correct.<br/><br/>After completing this, I moved on to writing the box ray tracer.<br/><br/><div class="card-title h5">Ray Tracing a Box</div>Scratchapixel has an excellent post on ray-box intersection that I followed in order to implement box ray tracing. That post can be found<i><a href="https://www.scratchapixel.com/lessons/3d-basic-rendering/minimal-ray-tracer-rendering-simple-shapes/ray-box-intersection"> here.</a></i><br/><br/>The basic idea is to find the intersection points of the ray and the planes corresponding to the box’s minimum and maximum extents. You can then determine if these points are on the box by analyzing the order in which they hit. For example, as displayed by the image below, if you hit the minimum X after you hit the maximum Y, you must have missed the box.<br/><br/><img src="../sap_miss_rb.png" style="width:25%;max-width:666px;padding-right:19px" class=""/><br/><br/>One unintuitive bit of this is that it swaps the minimum and maximum T values depending on which occurs first. I think about this as adjusting for the view of the camera. For example, if we&#x27;re located on the +X side of the cube and looking down -X, the minimum T will actually corresponding to the +X plane, not the -X plane.<br/><br/>Most of my code is the same as <i>Scratchapixel’s</i>, but I did add some additional logic to return the color corresponding to the intersected plane. Red for either X plane, green for either Y plane, and blue for either Z plane. Grey is returned if the ray misses the box.<br/><br/><div class="card-title h5">Camera Controls and Debug Stats</div>Since I already had camera position programmed into the shader, I decided to create a constant buffer I could pass to the pixel shader containing the camera position. This allows me to drive the camera position from the CPU. Using Dear ImGui, I created a debug window with sliders to modify the camera X, Y, and Z positions.<br/><br/>Lastly, I added FPS and frame time information to the debug window. I use the chrono library to get time stamps before and after the frame, then subtract these to get frame time in milliseconds. This time is then used to calculate the FPS.<br/><br/></div></div></div><br/></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/svo_update1/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-a407cf3765e733778079.js"],"app":["/app-c9959bfdc16894310609.js"],"component---src-pages-about-js":["/component---src-pages-about-js-50e00aef196e59bc65b5.js"],"component---src-pages-blog-js":["/component---src-pages-blog-js-4ccdbf66fefa83efac0b.js"],"component---src-pages-cel-shade-js":["/component---src-pages-cel-shade-js-ca85c40fd0dc961a9afb.js"],"component---src-pages-fiea-js":["/component---src-pages-fiea-js-3e5a85163a24ccbb3430.js"],"component---src-pages-index-js":["/component---src-pages-index-js-269cbb643b883cb8dbb3.js"],"component---src-pages-resume-js":["/component---src-pages-resume-js-f550664c429804c235a9.js"],"component---src-pages-snow-effect-js":["/component---src-pages-snow-effect-js-3e12d86bd376e5256fa1.js"],"component---src-pages-svo-update-1-js":["/component---src-pages-svo-update-1-js-6dffdd8aef8b45458b16.js"],"component---src-pages-svo-update-2-js":["/component---src-pages-svo-update-2-js-b4c3a9c587c838ce27bd.js"],"component---src-pages-svo-update-3-js":["/component---src-pages-svo-update-3-js-2d2301d86d0526ca25d3.js"],"component---src-pages-tree-gen-js":["/component---src-pages-tree-gen-js-fdaadf6f53da71c1bc80.js"],"component---src-pages-ultrastack-js":["/component---src-pages-ultrastack-js-0734814ca9b34d217f2b.js"]};/*]]>*/</script><script src="/polyfill-a407cf3765e733778079.js" nomodule=""></script><script src="/component---src-pages-svo-update-1-js-6dffdd8aef8b45458b16.js" async=""></script><script src="/commons-a30d9b8c89d158d4c38c.js" async=""></script><script src="/app-c9959bfdc16894310609.js" async=""></script><script src="/framework-712d0c71a05a512b21eb.js" async=""></script><script src="/webpack-runtime-9ed386a0224f94bdbae9.js" async=""></script></body></html>